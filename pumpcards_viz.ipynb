{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "import requests\n",
    "import psutil\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/areed145/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights('model.h5')\n",
    "print('Loaded model from disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600\n"
     ]
    }
   ],
   "source": [
    "input_files = glob.glob('arrays/*.npz')\n",
    "print(len(input_files))\n",
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "fs = []\n",
    "\n",
    "for file in input_files:\n",
    "    loaded = np.load(file)\n",
    "    Xs.append(loaded['X'])\n",
    "    ys.append(loaded['y'])\n",
    "    fs.append(file)\n",
    "    \n",
    "X_ = np.array(Xs)\n",
    "y_ = np.array(ys)\n",
    "f_ = np.array(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 5\n",
    "Xs_r = []\n",
    "ys_r = []\n",
    "fs_r = []\n",
    "for class_name in np.unique(y_):\n",
    "    Xc_ = X_[y_==class_name]\n",
    "    yc_ = y_[y_==class_name]\n",
    "    fc_ = f_[y_==class_name]\n",
    "    for sample in range(samples):\n",
    "        idx = random.randint(0,len(Xc_)-1)\n",
    "        Xs_r.append(Xc_[idx])\n",
    "        ys_r.append(yc_[idx])\n",
    "        fs_r.append(fc_[idx])\n",
    "        \n",
    "X = np.array(Xs_r)\n",
    "y = np.array(ys_r)\n",
    "f = np.array(fs_r)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_)\n",
    "del(y_)\n",
    "del(f_)\n",
    "del(Xs)\n",
    "del(ys)\n",
    "del(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 0]\n",
      " [0 0 5 0 0 0 0]\n",
      " [0 0 0 5 0 0 0]\n",
      " [1 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 5 0]\n",
      " [0 0 0 0 0 0 5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a418fe240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "cm = confusion_matrix(np.argmax(y, axis=1), np.argmax(y_pred, axis=1))\n",
    "print(cm)\n",
    "plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = {\n",
    "    -99:'nan',\n",
    "    0:'normal',\n",
    "    1:'fluid_pound',\n",
    "    2:'standing_valve',\n",
    "    3:'sticking',\n",
    "    4:'barrel_leak',\n",
    "    5:'gas',\n",
    "    6:'bad_data',\n",
    "}\n",
    "\n",
    "def map2layer(x, layer):\n",
    "    feed_dict = dict(zip([model.layers[0].input], [x.copy()]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "X_shap = X[:,:,:,:]\n",
    "ranked_outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.GradientExplainer(\n",
    "    (model.layers[layer].input, model.layers[-1].output), \n",
    "    map2layer(X_shap.copy(), layer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_explain = X[::samples,:,:,:]\n",
    "y_explain = np.argmax(y[::samples,:], axis=1)\n",
    "f_explain = f[::samples]\n",
    "shap_values, indexes = explainer.shap_values(\n",
    "    map2layer(X_explain, layer), \n",
    "    ranked_outputs=ranked_outputs\n",
    ")\n",
    "index_names = np.vectorize(lambda x: state_map[x])(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in range(len(X_explain)):\n",
    "    label = state_map[y_explain[x]]\n",
    "    card = 'cards/'+f_explain[x][7:-4]+'.csv'\n",
    "    df_card = pd.read_csv(card)\n",
    "    channels = ['position','acceleration','load']\n",
    "    titles = ['card: '+label]\n",
    "    for ch in range(3):\n",
    "        titles.append('truth: '+label+': '+channels[ch])\n",
    "        for ro in range(ranked_outputs):\n",
    "            titles.append(str(ro)+': '+index_names[x][ro]+': '+channels[ch])\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=ranked_outputs+2,\n",
    "        specs=[\n",
    "            [{'rowspan': 3}, {}, {}, {}],\n",
    "            [None, {}, {}, {}],\n",
    "            [None, {}, {}, {}]\n",
    "        ],\n",
    "        horizontal_spacing = 0.02,\n",
    "        vertical_spacing = 0.05,\n",
    "        shared_xaxes=True,\n",
    "        shared_yaxes=True,\n",
    "        subplot_titles=titles,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_card['pos(in)'].values,\n",
    "                y=df_card['Load_1(lbs)'].values,\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=df_card['acc(in/s/s)'].values,\n",
    "                    colorscale='Viridis',\n",
    "                    showscale=False,\n",
    "                ),\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    for ch in range(3):\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=np.rot90(np.rot90(np.rot90(X_explain[x][:,:,ch]))),\n",
    "                colorscale='Viridis',\n",
    "                showscale=False,\n",
    "                xaxis='x2',\n",
    "                yaxis='y2',\n",
    "            ),\n",
    "            row=ch+1, col=2\n",
    "        )\n",
    "        for ro in range(ranked_outputs):\n",
    "            endpt = np.quantile(np.abs(shap_values[ro][x][:,:,ch]), 0.99)\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=np.rot90(np.rot90(np.rot90(shap_values[ro][x][:,:,ch]))),\n",
    "                    zmin=-endpt,\n",
    "                    zmax=endpt,\n",
    "                    colorscale='Picnic',\n",
    "                    showscale=False,\n",
    "                    xaxis='x2',\n",
    "                    yaxis='y2',\n",
    "                ),\n",
    "                row=ch+1, col=ro+3\n",
    "            )\n",
    "            \n",
    "            \n",
    "    fig.update_layout(\n",
    "        height=300,\n",
    "        width=1200,\n",
    "#         title=label,\n",
    "#         xaxis_title=\"x Axis Title\",\n",
    "#         yaxis_title=\"y Axis Title\",\n",
    "        margin=dict(l=50, r=10, t=40, b=10),\n",
    "        xaxis2=dict(\n",
    "            autorange=True,\n",
    "            showgrid=False,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            autorange=True,\n",
    "            showgrid=False,\n",
    "            ticks='',\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        font=dict(\n",
    "#             family=\"Courier New, monospace\",\n",
    "            size=10,\n",
    "            color=\"#7f7f7f\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for i in fig['layout']['annotations']:\n",
    "        i['font']['size'] = 8\n",
    "    \n",
    "#     fig.show()\n",
    "    fig.write_image('images/'+label+'.svg')\n",
    "    fig.write_image('images/'+label+'.png')\n",
    "    fig.write_html('plots/'+label+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
